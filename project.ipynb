{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15c615c6",
   "metadata": {},
   "source": [
    "# Part A - Feature Extraction\n",
    "\n",
    "## 1. Feature Extraction\n",
    "\n",
    "This part of the coursework is involved with extracting all the features from the big folder of images celeba_selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ae406475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "EMBEDDINGS_FILE = \"extracted_features.npz\"\n",
    "NUM_IMAGES_TO_PROCESS = 20000\n",
    "IMAGE_DIR = \"img_align_celeba\"\n",
    "ATTRIBUTE_FILE = \"list_attr_celeba.txt\"\n",
    "SAMPLE_ATTRIBUTES_FILENAME = \"celeba_sampled_attributes\"\n",
    "SELECTED_ATTRIBUTES = [\"Smiling\", \"Male\", \"Young\", \"Blond_Hair\", \"Wearing_Hat\"]\n",
    "PREDICTION_ATTRIBUTE = \"Smiling\"\n",
    "\n",
    "TRAINING_PERCENT = 0.7\n",
    "CALIB_PERCENT = 0.15\n",
    "\n",
    "RESET = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a82c862",
   "metadata": {},
   "source": [
    "First, we cut down the attribute dataset to only include the attributes we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a96043d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Smiling  Male  Young  Blond_Hair  Wearing_Hat\n",
      "000001.jpg        1    -1      1          -1           -1\n",
      "000002.jpg        1    -1      1          -1           -1\n",
      "000003.jpg       -1     1      1          -1           -1\n",
      "000004.jpg       -1    -1      1          -1           -1\n",
      "000005.jpg       -1    -1      1          -1           -1\n"
     ]
    }
   ],
   "source": [
    "# First we open the attribute file\n",
    "\n",
    "with open(ATTRIBUTE_FILE, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "\n",
    "# Extract the headers from first row\n",
    "\n",
    "columns = lines[1].strip().split()\n",
    "\n",
    "\n",
    "# Extract the data part (from line 2 onwards)\n",
    "\n",
    "dataRows = lines[2:]\n",
    "\n",
    "data = []\n",
    "imageNames = []\n",
    "for row in dataRows:\n",
    "    \n",
    "\n",
    "    # Seperating the image name (first column) from rest of the dataset\n",
    "    \n",
    "    parts = row.strip().split()\n",
    "    imageNames.append(parts[0])    \n",
    "    data.append([int(x) for x in parts[1:]])\n",
    "\n",
    "attributeData = pandas.DataFrame(data, columns=columns, index=imageNames)\n",
    "\n",
    "\n",
    "# Now we create the subset based on our specific attributes\n",
    "\n",
    "cutAttributes = attributeData[SELECTED_ATTRIBUTES]\n",
    "print(cutAttributes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcb2ed2",
   "metadata": {},
   "source": [
    "The attribute dataset is now sampled randomly based on the sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3ff577a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled attributes saved to: celeba_sampled_attributes.csv\n"
     ]
    }
   ],
   "source": [
    "# Have random_state filled in to ensure consistency for testing\n",
    "\n",
    "sampledAttributes = cutAttributes.sample(n=NUM_IMAGES_TO_PROCESS, random_state=42)\n",
    "sampledImageNames = sampledAttributes.index.to_list()\n",
    "sampledAttributes.to_csv(SAMPLE_ATTRIBUTES_FILENAME + \".csv\", index=True)\n",
    "print(f\"Sampled attributes saved to: {SAMPLE_ATTRIBUTES_FILENAME}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef397e3",
   "metadata": {},
   "source": [
    "Below is the code for executing the feature extraction process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6e67208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures():\n",
    "\n",
    "    # First we skip this expensive step if feature file already exists.\n",
    "\n",
    "    if not RESET:\n",
    "        if not os.path.exists(EMBEDDINGS_FILE):\n",
    "            print(\"Embeddings file missing — need to re-extract.\")\n",
    "        else:\n",
    "            # Load existing embeddings\n",
    "            data = numpy.load(EMBEDDINGS_FILE)\n",
    "            existing_embeddings = data[\"embeddings\"]\n",
    "            savedImageNames = data[\"image_names\"]\n",
    "\n",
    "            # Load sampled attribute list\n",
    "            sampledAttributes = pandas.read_csv(SAMPLE_ATTRIBUTES_FILENAME + \".csv\", index_col=0)\n",
    "            currentImageNames = sampledAttributes.index.tolist()\n",
    "\n",
    "            if len(currentImageNames) != len(savedImageNames):\n",
    "                print(\"Number of images changed — re-extracting.\")\n",
    "            \n",
    "            # Check 2 — embeddings size matches?\n",
    "            elif existing_embeddings.shape[0] != len(currentImageNames):\n",
    "                print(\"Number of embeddings does not match sampled images: re-extracting.\")\n",
    "\n",
    "            # Check 3 — 1-by-1 filename match\n",
    "            elif not numpy.array_equal(currentImageNames, savedImageNames):\n",
    "                print(\"Image order or content mismatch: re-extracting.\")\n",
    "\n",
    "            else:\n",
    "                print(\"Embeddings match sampled image list. Skipping extraction.\")\n",
    "                return\n",
    "            \n",
    "\n",
    "    # We now load the pre-trained Vision Transformer and set it to evaluation mode\n",
    "\n",
    "    device = torch.device(\"cuda\")\n",
    "    vit = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1).to(device)\n",
    "    vit.eval()\n",
    "\n",
    "\n",
    "    # Preprocessing is defined; resizing, centre-cropping to 224x224, converted to tensors, and normalised to match ImageNet training\n",
    "\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "\n",
    "    # List of images is prepared from feature list earlier\n",
    "\n",
    "    sampledAttributes = pandas.read_csv(SAMPLE_ATTRIBUTES_FILENAME + \".csv\", index_col=0)\n",
    "    sampledImageNames = sampledAttributes.index.tolist()\n",
    "    \n",
    "\n",
    "\n",
    "    allFeatures = []\n",
    "\n",
    "\n",
    "    # Features are extracted for each image\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for fname in tqdm(sampledImageNames, desc=\"Extracting ViT Feature Embeddings\", colour=\"#ebbcba\"):\n",
    "            img = Image.open(os.path.join(IMAGE_DIR, fname)).convert(\"RGB\")\n",
    "            x = preprocess(img).unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "            ## Forward pass to get feature embeddings without classification head\n",
    "\n",
    "            x_processed = vit._process_input(x)\n",
    "            n = x_processed.shape[0]\n",
    "            \n",
    "            batch_class_token = vit.class_token.expand(n, -1, -1)\n",
    "            x_with_token = torch.cat([batch_class_token, x_processed], dim=1)\n",
    "\n",
    "            encoded_features = vit.encoder(x_with_token)\n",
    "            features = encoded_features[:, 0]\n",
    "\n",
    "            allFeatures.append(features.cpu().numpy().flatten())\n",
    "    \n",
    "\n",
    "    all_features_np = numpy.array(allFeatures)\n",
    "    print(f\"Feature matrix shape: {all_features_np.shape}\")\n",
    "\n",
    "\n",
    "    # Save feature embeddings for future use\n",
    "\n",
    "    numpy.savez(\n",
    "        EMBEDDINGS_FILE, \n",
    "        embeddings=all_features_np,\n",
    "        image_names=numpy.array(sampledImageNames)\n",
    "    )\n",
    "    print(f\"Embeddings + image names saved to '{EMBEDDINGS_FILE}'.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "1688c6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings match sampled image list. Skipping extraction.\n"
     ]
    }
   ],
   "source": [
    "extractFeatures()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8e51e3",
   "metadata": {},
   "source": [
    "## 2. Training the Classifiers\n",
    "\n",
    "First, we need top load the features and labels generated in part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4a3c33ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = numpy.load(EMBEDDINGS_FILE)\n",
    "features = data[\"embeddings\"]\n",
    "sampledAttributes = pandas.read_csv(SAMPLE_ATTRIBUTES_FILENAME + \".csv\", index_col=0)\n",
    "\n",
    "\n",
    "# Only want to confirm if the image is similing or not\n",
    "\n",
    "labels = sampledAttributes[PREDICTION_ATTRIBUTE].values\n",
    "\n",
    "# Since the attribute data records binary values as -1 and 1, we need to convert to 0 and 1 for Gaussian/Normal classifier\n",
    "\n",
    "labels = ((labels + 1) // 2).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2567e277",
   "metadata": {},
   "source": [
    "Now, the split sizes need to be computed to ensure the correct number of cases for each data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a21cfdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSize = int(TRAINING_PERCENT * NUM_IMAGES_TO_PROCESS)\n",
    "calibSize = int(CALIB_PERCENT * NUM_IMAGES_TO_PROCESS)\n",
    "testSize = NUM_IMAGES_TO_PROCESS - trainSize - calibSize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d0a8b1",
   "metadata": {},
   "source": [
    "The datasets can now be produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e27ef12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (14000, 768) (14000,)\n",
      "Calibration: (3000, 768) (3000,)\n",
      "Test: (3000, 768) (3000,)\n"
     ]
    }
   ],
   "source": [
    "# Training Set\n",
    "\n",
    "\n",
    "numpy.random.seed(42)\n",
    "\n",
    "shuffledIndicies = numpy.random.permutation(NUM_IMAGES_TO_PROCESS)\n",
    "\n",
    "trainEnd = trainSize\n",
    "calibEnd = trainSize + calibSize\n",
    "\n",
    "trainIndex = shuffledIndicies[:trainEnd]\n",
    "calibIndex = shuffledIndicies[trainEnd:calibEnd]\n",
    "testIndex = shuffledIndicies[calibEnd:]\n",
    "\n",
    "XTrain = features[trainIndex]\n",
    "yTrain = labels[trainIndex]\n",
    "\n",
    "# Calibration Set\n",
    "\n",
    "XCalib = features[calibIndex]\n",
    "yCalib = labels[calibIndex]\n",
    "\n",
    "# Testing Set\n",
    "\n",
    "XTest = features[testIndex]\n",
    "yTest = labels[testIndex]\n",
    "\n",
    "print(\"Train:\", XTrain.shape, yTrain.shape)\n",
    "print(\"Calibration:\", XCalib.shape, yCalib.shape)\n",
    "print(\"Test:\", XTest.shape, yTest.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7a9f29",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier modelling each feature as an independent Gaussian (Normal) Distribution\n",
    "\n",
    "We are going to define a class called GaussianNaiveBayes that will contain the functions for training, and making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "2cec4abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNaiveBayes:\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.labelValues = None\n",
    "        self.means = None\n",
    "        self.variances = None\n",
    "        self.priors = None\n",
    "\n",
    "    def train(self, X, y):\n",
    "\n",
    "        # We need to first indentify all our unique values our labels can hold\n",
    "\n",
    "        self.labelValues = numpy.unique(y)\n",
    "\n",
    "        self.means = {}\n",
    "        self.variances = {}\n",
    "        self.priors = {}\n",
    "\n",
    "        # We loop through all possible label values and identify the training samples belonging to the label value\n",
    "\n",
    "        for labelValue in self.labelValues:\n",
    "\n",
    "            # Selects all samples in dataset X that have that label value \n",
    "\n",
    "            XsWithLabelValue = X[y == labelValue]\n",
    "\n",
    "            # Compute mean and variance of each feature for this class\n",
    "\n",
    "            self.means[labelValue] = XsWithLabelValue.mean(axis=0)\n",
    "            self.variances[labelValue] = XsWithLabelValue.var(axis=0)\n",
    "\n",
    "            # Compute the prior probability that a random sample will have the same label value\n",
    "\n",
    "            self.priors[labelValue] = len(XsWithLabelValue) / len(X)\n",
    "\n",
    "\n",
    "    \n",
    "    def gaussianPDF(self, x, mean, variance):\n",
    "\n",
    "        # If every feature has the exact same value for a specific label value then variance will be 0, so replace every 0 with tiny value just in case\n",
    "\n",
    "        variance = numpy.where(variance == 0, 1e-6, variance)\n",
    "\n",
    "        normCoeff = 1.0 / numpy.sqrt(2.0 * numpy.pi * variance)\n",
    "\n",
    "        exponent = numpy.exp(- ( (x - mean) ** 2 / (2 * variance) ))\n",
    "\n",
    "        return normCoeff * exponent\n",
    "\n",
    "        \n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        for sample in X:\n",
    "            \n",
    "            labelValuePosteriors = {}\n",
    "\n",
    "            for labelValue in self.labelValues:\n",
    "\n",
    "                logPrior = numpy.log(self.priors[labelValue])\n",
    "\n",
    "                featureLogLiklihoods = numpy.log(self.gaussianPDF(sample, self.means[labelValue], self.variances[labelValue]))\n",
    "                \n",
    "                logLiklihood = numpy.sum(featureLogLiklihoods)\n",
    "\n",
    "                labelValuePosteriors[labelValue] = logPrior + logLiklihood\n",
    "\n",
    "            bestLabelValue = max(labelValuePosteriors, key=labelValuePosteriors.get)\n",
    "            predictions.append(bestLabelValue)\n",
    "\n",
    "        return numpy.array(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a094eb",
   "metadata": {},
   "source": [
    "Now that the class has been defined we can use it to see how effective the naiive bayes classifier is for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d15cb187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.702\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNaiveBayes()\n",
    "\n",
    "gnb.train(XTrain, yTrain)\n",
    "yPred = gnb.predict(XTest)\n",
    "\n",
    "accuracy = numpy.mean(yPred == yTest)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
